# STORM 长文本生成

## STORM 简介

[STORM (Synthesis of Topic Outlines through Retrieval and Multi-perspective Question Asking)](https://github.com/stanford-oval/storm) 是一篇使用LLM生成Wiki风格长文章的研究工作，可点击github链接查看论文和代码仓库。

STORM将写作分为两步：
1. 预写作阶段。预写作阶段，通过搜索互联网内容和虚拟作家与专家的多轮对话，形成写作大纲。
2. 章节写作阶段。对每个章节分别写作，并使用子章节作为查询关键词来召回之前互联网搜索的内容作为上下文。

如上面两条的概述并不能解释清楚，下面是我们实现的STORM的具体流程图和细节，以及一些观点：

1. 首先，生成带着不同观点的作家，这点非常有启发。很多时候，面对一个想要探究的陌生话题，即使有强大的LLM，我们的窘境是“不知道我们不知道的”。我们可能不能有效地从更多的角度分析话题，我们可能无法问出关键的问题。

这里我觉得官方的实现有一点不鲁棒/很局限的地方，寻找话题是从LLM输出相似的话题url链接开始的。当然，LLM训练的数据集包含wiki数据集，但是不同模型的表现还是存在差异的，有时模型会不遵循指令(不输出链接)，有时候会出现一丢丢幻觉，即链接是无效的。

如果要扩展STORM，我们认为很必要的一步是替换掉这里，例如，最直接的想法是使用LLM生成查询，并使用搜索引擎，但目的依旧是对话题生成多种观点/角度。

2. 接着，模拟不同观点的作家和同一个专家(带搜索功能)的多轮对话。多轮对话非常有意思，你能看到带着不同观点的4轮左右会话，关注话题的不同方面。专家会从话题开始，生成一些搜索关键词，并利用搜索引擎索引网页摘要，并存储下来以供后续召回使用。


3. 然后，生成文章大纲，包括章节和子章节。前面所有的过程，都是为了生成这个写作大纲。先让模型直接生成大纲草稿，再给LLM大纲草稿和对话历史(对话历史很长，这一步很耗费input token)，优化大纲。结合最后的章节写作阶段来看，这里生成的优化大纲是为了作为关键词召回搜索的内容，不免让人觉得有些浪费。

4. 最后，逐章节写作。给定章节名，如前面所述，使用大纲中的子章节名作为关键词检索并召回搜索内容。仅仅使用子章节名作为检索关键词的[原因](https://github.com/stanford-oval/storm/issues/30)是LLM重新生成章节的子章节内容，可以更长、更一致(Wiki人类作者的反馈)，有可能每个子章节LLM生成会带来子章节间的不一致。


## 我们的STORM实现

[STORM](https://github.com/stanford-oval/storm) 在四月初进行了一次彻底的重构，支持更多自定义风格的长文本生成。我们在四月官方重构发布前开始了代码重构，并且之后也参考了官方代码并增加了一些新的抽象。对比官方，差异不大，基本保持官方代码一直的流程。我们的STORM代码没有依赖`dspy`，而是原生的保存prompt，和LLM进行chat的方式。

我们的STORM实现在agent的框架下，`storm_agent`作为一种服务类型的agent，提供长文本的生成功能，之后也会从wiki类型的长文本扩展到其他类型的文本，例如技术博客等。
